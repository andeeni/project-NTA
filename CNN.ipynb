{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYpDsiD9-t4T"
      },
      "source": [
        "## Load the dataset and create the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ihvCKQAs-Hcm",
        "outputId": "a301fb96-9921-4313-b002-dbf832d8c97c"
      },
      "source": [
        "!pip install dvc"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dvc\n",
            "  Downloading dvc-2.8.3-py3-none-any.whl (399 kB)\n",
            "\u001b[K     |████████████████████████████████| 399 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting grandalf==0.6\n",
            "  Downloading grandalf-0.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.45.0 in /usr/local/lib/python3.7/dist-packages (from dvc) (4.62.3)\n",
            "Requirement already satisfied: pydot>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from dvc) (1.3.0)\n",
            "Collecting voluptuous>=0.11.7\n",
            "  Downloading voluptuous-0.12.2.tar.gz (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting funcy>=1.14\n",
            "  Downloading funcy-1.16-py2.py3-none-any.whl (32 kB)\n",
            "Collecting pygtrie>=2.3.2\n",
            "  Downloading pygtrie-2.4.2.tar.gz (35 kB)\n",
            "Collecting rich>=10.13.0\n",
            "  Downloading rich-10.15.2-py3-none-any.whl (214 kB)\n",
            "\u001b[K     |████████████████████████████████| 214 kB 36.0 MB/s \n",
            "\u001b[?25hCollecting ply>=3.9\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting shtab<2,>=1.3.4\n",
            "  Downloading shtab-1.5.2-py2.py3-none-any.whl (14 kB)\n",
            "Collecting pathspec<0.10.0,>=0.9.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting ruamel.yaml>=0.17.11\n",
            "  Downloading ruamel.yaml-0.17.17-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 44.4 MB/s \n",
            "\u001b[?25hCollecting zc.lockfile>=1.2.1\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting flatten-dict<1,>=0.4.1\n",
            "  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from dvc) (4.8.2)\n",
            "Collecting gitpython>3\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 48.6 MB/s \n",
            "\u001b[?25hCollecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting python-benedict>=0.24.2\n",
            "  Downloading python_benedict-0.24.3-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 40 kB/s \n",
            "\u001b[?25hCollecting nanotime>=0.5.2\n",
            "  Downloading nanotime-0.5.2.tar.gz (3.2 kB)\n",
            "Collecting distro>=1.3.0\n",
            "  Downloading distro-1.6.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from dvc) (0.10.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
            "\u001b[K     |████████████████████████████████| 296 kB 35.4 MB/s \n",
            "\u001b[?25hCollecting aiohttp-retry>=2.4.5\n",
            "  Downloading aiohttp_retry-2.4.6-py3-none-any.whl (7.7 kB)\n",
            "Collecting diskcache>=5.2.1\n",
            "  Downloading diskcache-5.3.0-py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from dvc) (0.4.8)\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from dvc) (0.8.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from dvc) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-resources>=5.2.2 in /usr/local/lib/python3.7/dist-packages (from dvc) (5.4.0)\n",
            "Collecting dulwich>=0.20.23\n",
            "  Downloading dulwich-0.20.26-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 39.0 MB/s \n",
            "\u001b[?25hCollecting pygit2>=1.5.0\n",
            "  Downloading pygit2-1.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 37.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.7/dist-packages (from dvc) (2.6.3)\n",
            "Collecting dictdiffer>=0.8.1\n",
            "  Downloading dictdiffer-0.9.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting dpath<3,>=2.0.2\n",
            "  Downloading dpath-2.0.5-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from dvc) (1.4.4)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.7/dist-packages (from dvc) (21.3)\n",
            "Collecting configobj>=5.0.6\n",
            "  Downloading configobj-5.0.6.tar.gz (33 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from dvc) (2.23.0)\n",
            "Collecting fsspec[http]>=2021.10.1\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 49.1 MB/s \n",
            "\u001b[?25hCollecting flufl.lock>=5\n",
            "  Downloading flufl.lock-6.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.7/dist-packages (from dvc) (3.0.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from grandalf==0.6->dvc) (0.16.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 33.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from configobj>=5.0.6->dvc) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from dulwich>=0.20.23->dvc) (2021.10.8)\n",
            "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.7/dist-packages (from dulwich>=0.20.23->dvc) (1.24.3)\n",
            "Collecting atpublic\n",
            "  Downloading atpublic-2.3.tar.gz (16 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->dvc) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pygit2>=1.5.0->dvc) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from pygit2>=1.5.0->dvc) (1.5.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.4.0->pygit2>=1.5.0->dvc) (2.21)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from python-benedict>=0.24.2->dvc) (2.8.2)\n",
            "Collecting python-fsutil\n",
            "  Downloading python_fsutil-0.5.0-py3-none-any.whl (11 kB)\n",
            "Collecting mailchecker\n",
            "  Downloading mailchecker-4.1.1.tar.gz (222 kB)\n",
            "\u001b[K     |████████████████████████████████| 222 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from python-benedict>=0.24.2->dvc) (5.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from python-benedict>=0.24.2->dvc) (3.13)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting phonenumbers\n",
            "  Downloading phonenumbers-8.12.38-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 37.6 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->dvc) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->dvc) (3.0.4)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.13.0->dvc) (2.6.1)\n",
            "Collecting ruamel.yaml.clib>=0.1.2\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zc.lockfile>=1.2.1->dvc) (57.4.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 49.0 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 48.7 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 49.6 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->aiohttp-retry>=2.4.5->dvc) (2.0.8)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->aiohttp-retry>=2.4.5->dvc) (21.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->python-benedict>=0.24.2->dvc) (0.2.5)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->python-benedict>=0.24.2->dvc) (1.3)\n",
            "Building wheels for collected packages: configobj, flufl.lock, nanotime, pygtrie, voluptuous, atpublic, ftfy, mailchecker\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-py3-none-any.whl size=34546 sha256=e4998752d061aad069a5aad9d08b5fde4a2c37bbdb60bc165460008bf09fdefc\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/c4/19/13d74440f2a571841db6b6e0a273694327498884dafb9cf978\n",
            "  Building wheel for flufl.lock (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flufl.lock: filename=flufl.lock-6.0-py3-none-any.whl size=11995 sha256=7f19d3e28d258c4edcc56c620cc8902e831efec836c6619a00b16607df534ff8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/00/5c/f761a3cd38e03e313676e8c6bff1743d3dc280d58ab3f16ecd\n",
            "  Building wheel for nanotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nanotime: filename=nanotime-0.5.2-py3-none-any.whl size=2440 sha256=7b54fa67b5d2ea431f500e96395494bcaa06836eb72245cc2849a01264f95cf6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/92/aa/456d462c908b4e210c3928f778d28f94049fc9e47af8b191c9\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygtrie: filename=pygtrie-2.4.2-py3-none-any.whl size=19062 sha256=99cdc898d61f1ac616883641424386e9405395da0b6efff663c0830ea9901bc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/f8/ba/1d828b1603ea422686eb694253a43cb3a5901ea4696c1e0603\n",
            "  Building wheel for voluptuous (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for voluptuous: filename=voluptuous-0.12.2-py3-none-any.whl size=29562 sha256=0241ce34fb2a8c13238e48891a8bf3298028524476af637891df59c1a3320c40\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/40/e9/5aba7699054584e118b04cc18d4d8f1f15f27af4a0d65ef4b4\n",
            "  Building wheel for atpublic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for atpublic: filename=atpublic-2.3-py3-none-any.whl size=5033 sha256=6d448905d155950eecbeafbd5e5286a6e3fd247220f0102cc624381797360c06\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/d9/0f/54be2ecb4bcb1612f987f0b6482d88fa7f3e43d3946f36a32a\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=2d36376d373d55fcfc2b1716312251dfb7c6aae160fef4d87000dabe2e1b1872\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for mailchecker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mailchecker: filename=mailchecker-4.1.1-py3-none-any.whl size=222870 sha256=1c47a65ec3999b64c28d208660c1d93cdf361fe6d1929c200f1019c3030062b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/b7/c8/9c752c0de8b761960d6591758d7569ff8d4ce767a947c5ddf3\n",
            "Successfully built configobj flufl.lock nanotime pygtrie voluptuous atpublic ftfy mailchecker\n",
            "Installing collected packages: multidict, frozenlist, yarl, smmap, asynctest, async-timeout, aiosignal, xmltodict, ruamel.yaml.clib, python-fsutil, psutil, phonenumbers, mailchecker, gitdb, ftfy, fsspec, commonmark, colorama, atpublic, aiohttp, zc.lockfile, voluptuous, shtab, shortuuid, ruamel.yaml, rich, python-benedict, pygtrie, pygit2, ply, pathspec, nanotime, grandalf, gitpython, funcy, flufl.lock, flatten-dict, dulwich, dpath, distro, diskcache, dictdiffer, configobj, aiohttp-retry, dvc\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed aiohttp-3.8.1 aiohttp-retry-2.4.6 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 atpublic-2.3 colorama-0.4.4 commonmark-0.9.1 configobj-5.0.6 dictdiffer-0.9.0 diskcache-5.3.0 distro-1.6.0 dpath-2.0.5 dulwich-0.20.26 dvc-2.8.3 flatten-dict-0.4.2 flufl.lock-6.0 frozenlist-1.2.0 fsspec-2021.11.1 ftfy-6.0.3 funcy-1.16 gitdb-4.0.9 gitpython-3.1.24 grandalf-0.6 mailchecker-4.1.1 multidict-5.2.0 nanotime-0.5.2 pathspec-0.9.0 phonenumbers-8.12.38 ply-3.11 psutil-5.8.0 pygit2-1.7.1 pygtrie-2.4.2 python-benedict-0.24.3 python-fsutil-0.5.0 rich-10.15.2 ruamel.yaml-0.17.17 ruamel.yaml.clib-0.2.6 shortuuid-1.0.8 shtab-1.5.2 smmap-5.0.0 voluptuous-0.12.2 xmltodict-0.12.0 yarl-1.7.2 zc.lockfile-2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RIXO06f-bxS",
        "outputId": "7766e8e5-7580-42ce-d924-4959d73660e7"
      },
      "source": [
        "!dvc get https://github.com/iterative/aita_dataset aita_clean.csv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vVXzcRv-kcq"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('aita_clean.csv')\n",
        "df = df[df['score'] >= 10]\n",
        "df['text'] = df['title'] + df['body'].fillna('')\n",
        "lines = df['text']\n",
        "labels = df['is_asshole']\n",
        "new_df = df[['text', 'is_asshole']]\n",
        "new_df.reset_index(drop=True, inplace=True) \n",
        "train, test = train_test_split(new_df, test_size=0.3)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfw21JQU-nMt"
      },
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter, OrderedDict\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "EMBEDDING_DIM=50\n",
        "VOCAB_SIZE=20000\n",
        "\n",
        "# Load English tokenizer, tagger, parser and NER\n",
        "tokenizer = get_tokenizer('spacy', language='en')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq_OwOxh-q7b"
      },
      "source": [
        "# build the vocab\n",
        "counter = Counter()\n",
        "for i, line in enumerate(lines):\n",
        "    counter.update(tokenizer(str(line)))\n",
        "\n",
        "ordered_dict = OrderedDict(counter.most_common()[:VOCAB_SIZE])\n",
        "vocab = vocab(ordered_dict)\n",
        "\n",
        "# insert special tokens and set default index to 'unknown'\n",
        "vocab.insert_token('<PAD>', 0)\n",
        "vocab.insert_token('<UNK>', 1)\n",
        "vocab.set_default_index(1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oD0PGeP-2OQ"
      },
      "source": [
        "## Create embedding vectors from GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nolWE2o-4U4",
        "outputId": "0fa2b68f-16aa-40be-f784-6df53053274d"
      },
      "source": [
        "import torchtext as text\n",
        "\n",
        "# load glove embeddings\n",
        "vec = text.vocab.GloVe(name='6B', dim=50)\n",
        "# create the embedding matrix, a torch tensor in the shape (num_words+1, embedding_dim)\n",
        "word_emb = vec.get_vecs_by_tokens(vocab.get_itos())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:40, 5.37MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:14<00:00, 27734.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GhoaqwH_DQ-"
      },
      "source": [
        "## Build up train/test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4GXXk_3_BXr"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# transform input text to vectors\n",
        "def process_text(text):\n",
        "    return vocab(tokenizer(text))\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, lengths = [], [], []\n",
        "    for (_index, _text, _label) in batch:\n",
        "        label_list.append(_label)\n",
        "        processed_text = torch.tensor(process_text(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        lengths.append(processed_text.size(0))\n",
        "    # label must be in the same size as target\n",
        "    label_list = torch.tensor(label_list, dtype=torch.float)[:,None]\n",
        "\n",
        "    text_list = pad_sequence(text_list, batch_first=True)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.float)\n",
        "    return label_list.to(device), text_list.to(device), lengths.to(device)\n",
        "\n",
        "train_dataset = to_map_style_dataset(train.itertuples())\n",
        "test_dataset = to_map_style_dataset(test.itertuples())\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=128,\n",
        "                              shuffle=True, collate_fn=collate_batch)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Frqn-uAAwx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTMcustom(nn.Module):\n",
        "    def __init__(self, word_vec, embed_dim):\n",
        "        super().__init__()\n",
        "        # embeddingbag outputs the average of all the words in a sentence\n",
        "        self.embedding = nn.Embedding(*(word_vec.size())).from_pretrained(word_vec, freeze=False)\n",
        "        # Create a 1D-CNN use torch.nn.Conv1d and feed the output to the next LSTM layer. \n",
        "        self.cnn = torch.nn.Conv1d(in_channels=embed_dim, out_channels=20, kernel_size=2)\n",
        "        # Determine the input shape of this LSTM layer.\n",
        "        self.lstm = nn.LSTM(20, 200, 1, bidirectional=False, batch_first = True)\n",
        "\n",
        "        self.fc = nn.Linear(200, 1)\n",
        "                \n",
        "    def forward(self, text, lengths):\n",
        "        embedded = self.embedding(text) # (batch_size, sent_len, emb_size)\n",
        "        # Original sequence and embedding_dim can change after applying CNN, use torch.permute to transpose\n",
        "\n",
        "        embedded = torch.permute(embedded, (0, 2, 1)) # (batch_size, emb_size, sent_len)\n",
        "        \n",
        "        cnn_out = self.cnn(embedded) # (batch_size, emb_size, sent_len)\n",
        "\n",
        "        cnn_out = torch.permute(cnn_out, (0, 2, 1)) # (batch_size, sent_len, emb_size)\n",
        "\n",
        "        lstm_out,_ = self.lstm(cnn_out) # lstm_out is a 3d tensor (batch_size, seq_len, output_size)\n",
        "        \n",
        "        lstm_out = lstm_out[:, -1, :]\n",
        "\n",
        "        return torch.sigmoid(self.fc(lstm_out)) "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3swnoiTP_iqA"
      },
      "source": [
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 50\n",
        "\n",
        "    for idx, (label, text, lengths) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        # forward propagation\n",
        "        predicted_label = model(text, lengths)\n",
        "        # calculate loss and backpropagate to model paramters\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        # update parameters by stepping the optimizer\n",
        "        optimizer.step()\n",
        "        total_acc += ((predicted_label > 0.5) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, lengths) in enumerate(dataloader):\n",
        "            predicted_label = model(text, lengths)\n",
        "            loss = criterion(predicted_label, label)\n",
        "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As_Zg1vYGCRX"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23OkyNDt_kse",
        "outputId": "c676a91e-e10a-4250-e47d-8b10935b8206"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "model = LSTMcustom(word_vec=word_emb, embed_dim=EMBEDDING_DIM).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.BCELoss()\n",
        "total_accu = None\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(train_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |    50/  268 batches | accuracy    0.729\n",
            "| epoch   1 |   100/  268 batches | accuracy    0.733\n",
            "| epoch   1 |   150/  268 batches | accuracy    0.730\n",
            "| epoch   1 |   200/  268 batches | accuracy    0.718\n",
            "| epoch   1 |   250/  268 batches | accuracy    0.719\n",
            "| epoch   2 |    50/  268 batches | accuracy    0.720\n",
            "| epoch   2 |   100/  268 batches | accuracy    0.730\n",
            "| epoch   2 |   150/  268 batches | accuracy    0.724\n",
            "| epoch   2 |   200/  268 batches | accuracy    0.734\n",
            "| epoch   2 |   250/  268 batches | accuracy    0.724\n",
            "| epoch   3 |    50/  268 batches | accuracy    0.725\n",
            "| epoch   3 |   100/  268 batches | accuracy    0.719\n",
            "| epoch   3 |   150/  268 batches | accuracy    0.729\n",
            "| epoch   3 |   200/  268 batches | accuracy    0.722\n",
            "| epoch   3 |   250/  268 batches | accuracy    0.729\n",
            "| epoch   4 |    50/  268 batches | accuracy    0.726\n",
            "| epoch   4 |   100/  268 batches | accuracy    0.725\n",
            "| epoch   4 |   150/  268 batches | accuracy    0.721\n",
            "| epoch   4 |   200/  268 batches | accuracy    0.725\n",
            "| epoch   4 |   250/  268 batches | accuracy    0.733\n",
            "| epoch   5 |    50/  268 batches | accuracy    0.728\n",
            "| epoch   5 |   100/  268 batches | accuracy    0.716\n",
            "| epoch   5 |   150/  268 batches | accuracy    0.728\n",
            "| epoch   5 |   200/  268 batches | accuracy    0.738\n",
            "| epoch   5 |   250/  268 batches | accuracy    0.722\n",
            "| epoch   6 |    50/  268 batches | accuracy    0.722\n",
            "| epoch   6 |   100/  268 batches | accuracy    0.732\n",
            "| epoch   6 |   150/  268 batches | accuracy    0.724\n",
            "| epoch   6 |   200/  268 batches | accuracy    0.729\n",
            "| epoch   6 |   250/  268 batches | accuracy    0.728\n",
            "| epoch   7 |    50/  268 batches | accuracy    0.726\n",
            "| epoch   7 |   100/  268 batches | accuracy    0.732\n",
            "| epoch   7 |   150/  268 batches | accuracy    0.726\n",
            "| epoch   7 |   200/  268 batches | accuracy    0.730\n",
            "| epoch   7 |   250/  268 batches | accuracy    0.720\n",
            "| epoch   8 |    50/  268 batches | accuracy    0.722\n",
            "| epoch   8 |   100/  268 batches | accuracy    0.730\n",
            "| epoch   8 |   150/  268 batches | accuracy    0.723\n",
            "| epoch   8 |   200/  268 batches | accuracy    0.724\n",
            "| epoch   8 |   250/  268 batches | accuracy    0.731\n",
            "| epoch   9 |    50/  268 batches | accuracy    0.724\n",
            "| epoch   9 |   100/  268 batches | accuracy    0.723\n",
            "| epoch   9 |   150/  268 batches | accuracy    0.724\n",
            "| epoch   9 |   200/  268 batches | accuracy    0.731\n",
            "| epoch   9 |   250/  268 batches | accuracy    0.729\n",
            "| epoch  10 |    50/  268 batches | accuracy    0.731\n",
            "| epoch  10 |   100/  268 batches | accuracy    0.718\n",
            "| epoch  10 |   150/  268 batches | accuracy    0.722\n",
            "| epoch  10 |   200/  268 batches | accuracy    0.723\n",
            "| epoch  10 |   250/  268 batches | accuracy    0.732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B-VL9UCGFuO"
      },
      "source": [
        "## Model saving and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zff1FMjQ_2Ev",
        "outputId": "6e30ff26-ed53-4362-967e-7bc80d736a07"
      },
      "source": [
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "#save the parameters of a model\n",
        "torch.save(model.state_dict(), 'CNN_NTA_model.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state_dict:\n",
            "embedding.weight \t torch.Size([20002, 50])\n",
            "cnn.weight \t torch.Size([20, 50, 2])\n",
            "cnn.bias \t torch.Size([20])\n",
            "lstm.weight_ih_l0 \t torch.Size([800, 20])\n",
            "lstm.weight_hh_l0 \t torch.Size([800, 200])\n",
            "lstm.bias_ih_l0 \t torch.Size([800])\n",
            "lstm.bias_hh_l0 \t torch.Size([800])\n",
            "fc.weight \t torch.Size([1, 200])\n",
            "fc.bias \t torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFEtkbQgF4Ob",
        "outputId": "2a257c32-354f-45c0-8d45-2db5704136ab"
      },
      "source": [
        "accu_test = evaluate(test_dataloader)\n",
        "print('test accuracy {:8.2f}%'.format(accu_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy    92.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jw-Z6hhGW-i"
      },
      "source": [
        "def predict(sentence, model):\n",
        "    model.eval()\n",
        "    text_list = []\n",
        "    lengths = []\n",
        "    processed_text = torch.tensor(process_text(sentence), dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "    lengths.append(processed_text.size(0))\n",
        "    text_list = pad_sequence(text_list, batch_first=True)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.float)\n",
        "    with torch.no_grad():\n",
        "        predicted_label = model(text_list.to(device), lengths.to(device))\n",
        "    label = (predicted_label.cpu().numpy()[0] > 0.5)\n",
        "    if label == 0:\n",
        "        print('The predict label is : 0, and the class is no asshole with the probability of {}.'.format(1 - predicted_label.item()))\n",
        "    else:\n",
        "        print('The predict label is : 1, and the class is asshole with the probability of {}.'.format(predicted_label.item()))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jimFt6UnGLpX",
        "outputId": "4e5ba031-c3e7-4490-e143-33127b1090c8"
      },
      "source": [
        "sentence = test['text'].iloc[0]\n",
        "predict(sentence, model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predict label is : 0, and the class is no asshole with the probability of 0.6079334020614624.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKGU7oJEHg0M"
      },
      "source": [
        "## Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNqrBgUFHlzA",
        "outputId": "fa54069d-fa87-4114-e10e-575ca84a44ea"
      },
      "source": [
        "model = LSTMcustom(word_vec=word_emb, embed_dim=EMBEDDING_DIM).to(device)\n",
        "model.load_state_dict(torch.load('CNN_NTA_model.pt'))\n",
        "model.eval()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMcustom(\n",
              "  (embedding): Embedding(20002, 50)\n",
              "  (cnn): Conv1d(50, 20, kernel_size=(2,), stride=(1,))\n",
              "  (lstm): LSTM(20, 200, batch_first=True)\n",
              "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvCBeFrAtZS_",
        "outputId": "f4cd9304-8928-47a0-b5aa-822cb0306001"
      },
      "source": [
        "sentence = test['text'].iloc[50]\n",
        "predict(sentence, model)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predict label is : 0, and the class is no asshole with the probability of 0.6067976653575897.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wyc-KiEIRGY",
        "outputId": "1650f987-df84-4c47-c80f-d48998f67662"
      },
      "source": [
        "sentence = test['text'].iloc[100]\n",
        "predict(sentence, model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predict label is : 0, and the class is no asshole with the probability of 0.6054364144802094.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}